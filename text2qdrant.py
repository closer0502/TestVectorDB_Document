import os
import glob
import uuid
from pathlib import Path
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from tqdm import tqdm

# === è¨­å®š ===
DATA_DIR = "texts"
COLLECTION_NAME = "documents"
CHUNK_SIZE = 500  # æ–‡å­—æ•°ã§ãƒãƒ£ãƒ³ã‚¯åŒ–

# === ãƒ¢ãƒ‡ãƒ«ã¨Qdrantã®åˆæœŸåŒ– ===
model = SentenceTransformer("all-MiniLM-L6-v2")  # æ—¥æœ¬èªãªã‚‰ bge-small-ja ã«ã—ã¦ã‚‚OK
client = QdrantClient("localhost", port=6333)

# === ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆãªã‘ã‚Œã°ï¼‰ ===
if COLLECTION_NAME not in [col.name for col in client.get_collections().collections]:
    client.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE)
    )

# === ãƒãƒ£ãƒ³ã‚¯å‡¦ç† ===
def chunk_text(text, chunk_size=CHUNK_SIZE):
    chunks = []
    buf = ""
    for line in text.splitlines():
        if line.strip() == "":
            continue
        buf += line.strip() + "\n"
        if len(buf) >= chunk_size:
            chunks.append(buf.strip())
            buf = ""
    if buf:
        chunks.append(buf.strip())
    return chunks

# === ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»Qdrantç™»éŒ² ===
for filepath in glob.glob(f"{DATA_DIR}/*.*"):
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()
    title = Path(filepath).stem
    chunks = chunk_text(text)

    print(f"\n[+] å‡¦ç†ä¸­: {title} ({len(chunks)}ãƒãƒ£ãƒ³ã‚¯)")

    vectors = model.encode(chunks, show_progress_bar=True)

    points = []
    for i, (vec, chunk) in enumerate(zip(vectors, chunks)):
        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=vec.tolist(),
            payload={
                "title": title,
                "chunk_id": i + 1,
                "summary": chunk,
                "source": os.path.basename(filepath),
            }
        ))

    client.upsert(collection_name=COLLECTION_NAME, points=points)

print("\n[âœ“] ç™»éŒ²å®Œäº†")

# === CLIæ¤œç´¢ ===
while True:
    query = input("\nğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ï¼ˆçµ‚äº†ã¯ 'q'ï¼‰ï¼š ")
    if query.lower() == 'q':
        break
    vec = model.encode(query).tolist()
    results = client.search(collection_name=COLLECTION_NAME, query_vector=vec, top=3)

    print("\n--- æ¤œç´¢çµæœ ---")
    for r in results:
        print(f"[{r.payload['title']} - chunk {r.payload['chunk_id']}]\n{r.payload['summary']}\n---")
